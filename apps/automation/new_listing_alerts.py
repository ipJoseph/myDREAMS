"""
New Listing Alerts

Daily digest emails to buyers when matching properties hit the market.
Uses contact_requirements for matching criteria.

Cron: 0 8 * * * (Daily 8:00 AM)
"""

import os
import sqlite3
import json
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple

from apps.automation import config
from apps.automation.config import get_db_setting
from apps.automation.email_service import send_template_email

logging.basicConfig(level=getattr(logging, config.LOG_LEVEL))
logger = logging.getLogger(__name__)

# FUB client singleton (lazy loaded)
_fub_client = None


def get_fub_client():
    """Get or create FUB API client instance."""
    global _fub_client
    if _fub_client is None:
        api_key = os.getenv('FUB_API_KEY')
        if not api_key:
            logger.warning("FUB_API_KEY not set - note push disabled")
            return None

        try:
            from fub_core import FUBClient
            _fub_client = FUBClient(
                api_key=api_key,
                logger=logger
            )
            logger.info("FUB client initialized for note push")
        except ImportError:
            logger.warning("fub_core not installed - note push disabled")
            return None
        except Exception as e:
            logger.error(f"Failed to initialize FUB client: {e}")
            return None

    return _fub_client


def push_matches_to_fub(buyer: Dict, properties: List[Dict]) -> bool:
    """
    Push matched properties as a note to the buyer's FUB contact record.

    Args:
        buyer: Buyer dictionary with fub_id
        properties: List of matched property dictionaries

    Returns:
        True if note was created successfully
    """
    # Check if feature is enabled
    if not get_db_setting('fub_note_push_enabled', True):
        return False

    # Need FUB ID to push notes
    fub_id = buyer.get('fub_id')
    if not fub_id:
        logger.debug(f"No FUB ID for contact {buyer.get('id')} - skipping note push")
        return False

    # Get FUB client
    fub = get_fub_client()
    if not fub:
        return False

    # Build note content
    note_lines = [
        f"DREAMS Alert: {len(properties)} new listing(s) matched on {datetime.now().strftime('%B %d, %Y')}",
        ""
    ]

    for i, prop in enumerate(properties[:5], 1):  # Limit to 5 in note
        price_str = f"${prop.get('price', 0):,}" if prop.get('price') else "Price N/A"
        beds = prop.get('beds', '?')
        baths = prop.get('baths', '?')
        sqft = f"{prop.get('sqft', 0):,}" if prop.get('sqft') else '?'
        score = prop.get('match_score', 0)

        note_lines.append(f"{i}. {prop.get('address', 'Unknown')}, {prop.get('city', '')}")
        note_lines.append(f"   {price_str} | {beds}bd/{baths}ba | {sqft} sqft | Match: {score}%")

        # Add listing URL if available
        url = prop.get('listing_url') or prop.get('idx_url') or prop.get('redfin_url')
        if url:
            note_lines.append(f"   {url}")
        note_lines.append("")

    if len(properties) > 5:
        note_lines.append(f"... and {len(properties) - 5} more properties")
        note_lines.append("")

    note_lines.append("---")
    note_lines.append("Auto-generated by DREAMS New Listing Alerts")

    note_body = "\n".join(note_lines)

    # Push to FUB
    try:
        result = fub.create_note(person_id=int(fub_id), body=note_body)
        if result:
            logger.info(f"Pushed match note to FUB contact {fub_id}")
            try:
                from src.core.fub_audit import log_fub_write
                log_fub_write(module='new_listing_alerts', operation='create_note',
                              endpoint='notes', http_method='POST',
                              fub_person_id=int(fub_id),
                              payload_summary=f'DREAMS Alert: {len(properties)} new listing(s) matched')
            except Exception:
                pass
            return True
        else:
            logger.warning(f"Failed to push note to FUB contact {fub_id}")
            return False
    except Exception as e:
        logger.error(f"Error pushing note to FUB: {e}")
        return False


def get_db_connection():
    """Get database connection."""
    conn = sqlite3.connect(config.DATABASE_PATH)
    conn.row_factory = sqlite3.Row
    return conn


def get_new_listings(hours: int = 24) -> List[Dict[str, Any]]:
    """
    Get properties added in the last N hours.

    Args:
        hours: Look back period in hours

    Returns:
        List of new property dictionaries
    """
    cutoff = (datetime.now() - timedelta(hours=hours)).isoformat()
    conn = get_db_connection()

    try:
        listings = conn.execute('''
            SELECT
                id, mls_number, address, city, state, zip, county,
                list_price as price, beds, baths, sqft, acreage,
                property_type, status, views,
                photos, primary_photo, zillow_url, redfin_url, idx_url,
                captured_at as created_at
            FROM listings
            WHERE LOWER(status) = 'active'
            AND captured_at >= ?
            AND county IN ({})
        '''.format(','.join(['?' for _ in config.TRACKED_COUNTIES])),
            [cutoff] + config.TRACKED_COUNTIES
        ).fetchall()

        results = []
        for listing in listings:
            prop = dict(listing)

            # Use primary_photo, or parse first from photos JSON
            prop['photo_url'] = prop.get('primary_photo')
            if not prop['photo_url'] and prop.get('photos'):
                try:
                    photo_list = json.loads(prop['photos'])
                    prop['photo_url'] = photo_list[0] if photo_list else None
                except json.JSONDecodeError:
                    prop['photo_url'] = None

            # Determine best listing URL
            prop['listing_url'] = prop.get('idx_url') or prop.get('zillow_url') or prop.get('redfin_url')

            results.append(prop)

        logger.info(f"Found {len(results)} new listings in last {hours} hours")
        return results

    finally:
        conn.close()


def get_active_buyers() -> List[Dict[str, Any]]:
    """
    Get all active buyer contacts with their requirements.

    Returns:
        List of buyer dictionaries with consolidated requirements
    """
    conn = get_db_connection()

    try:
        buyers = conn.execute('''
            SELECT
                l.id,
                l.fub_id,
                l.first_name,
                l.last_name,
                l.email,
                l.heat_score,
                cr.price_min,
                cr.price_max,
                cr.beds_min,
                cr.baths_min,
                cr.sqft_min,
                cr.acreage_min,
                cr.counties,
                cr.cities,
                cr.property_types,
                cr.must_have_features,
                cr.views_required,
                cr.water_features,
                cr.overall_confidence
            FROM leads l
            LEFT JOIN contact_requirements cr ON cr.contact_id = l.id
            LEFT JOIN contact_workflow cw ON cw.contact_id = l.id
            WHERE l.type = 'buyer'
            AND l.email IS NOT NULL
            AND l.email != ''
            AND COALESCE(cw.workflow_status, 'active') = 'active'
            AND COALESCE(cw.current_stage, l.stage) NOT IN ('closed', 'lost')
        ''').fetchall()

        results = []
        for buyer in buyers:
            b = dict(buyer)

            # Parse JSON fields
            for field in ['counties', 'cities', 'property_types', 'must_have_features', 'views_required', 'water_features']:
                if b.get(field):
                    try:
                        b[field] = json.loads(b[field])
                    except json.JSONDecodeError:
                        b[field] = []
                else:
                    b[field] = []

            results.append(b)

        logger.info(f"Found {len(results)} active buyers with requirements")
        return results

    finally:
        conn.close()


def calculate_match_score(property: Dict[str, Any], buyer: Dict[str, Any]) -> Tuple[int, List[str]]:
    """
    Calculate how well a property matches a buyer's requirements.

    Args:
        property: Property dictionary
        buyer: Buyer dictionary with requirements

    Returns:
        Tuple of (match_score, list of matching criteria)
    """
    score = 0
    max_score = 0
    matching_criteria = []

    # Price match (30 points)
    max_score += 30
    if buyer.get('price_min') or buyer.get('price_max'):
        price = property.get('price', 0)
        price_min = buyer.get('price_min') or 0
        price_max = buyer.get('price_max') or float('inf')

        if price_min <= price <= price_max:
            score += 30
            matching_criteria.append('Price in range')
        elif price < price_min * 0.9:
            score += 15  # Under budget is okay
            matching_criteria.append('Under budget')
        elif price <= price_max * 1.1:
            score += 10  # Slightly over is acceptable
    else:
        score += 15  # No price requirement, give partial credit

    # Beds match (20 points)
    max_score += 20
    if buyer.get('beds_min'):
        if property.get('beds', 0) >= buyer['beds_min']:
            score += 20
            matching_criteria.append(f"{property['beds']}+ beds")
        elif property.get('beds', 0) == buyer['beds_min'] - 1:
            score += 10  # One less bed might work
    else:
        score += 10  # No requirement

    # Baths match (10 points)
    max_score += 10
    if buyer.get('baths_min'):
        if property.get('baths', 0) >= buyer['baths_min']:
            score += 10
            matching_criteria.append(f"{property['baths']}+ baths")
    else:
        score += 5

    # Location match (20 points)
    max_score += 20
    property_county = property.get('county', '').lower()
    property_city = property.get('city', '').lower()

    buyer_counties = [c.lower() for c in buyer.get('counties', [])]
    buyer_cities = [c.lower() for c in buyer.get('cities', [])]

    if buyer_counties or buyer_cities:
        if property_county in buyer_counties:
            score += 20
            matching_criteria.append(f"{property.get('county')} county")
        elif property_city in buyer_cities:
            score += 20
            matching_criteria.append(f"{property.get('city')}")
        elif not buyer_counties and not buyer_cities:
            score += 10  # No location requirement
    else:
        score += 10

    # Size match (10 points)
    max_score += 10
    if buyer.get('sqft_min'):
        if property.get('sqft', 0) >= buyer['sqft_min']:
            score += 10
            matching_criteria.append(f"{property['sqft']:,} sqft")
    else:
        score += 5

    # Acreage match (10 points)
    max_score += 10
    if buyer.get('acreage_min'):
        if property.get('acreage', 0) >= buyer['acreage_min']:
            score += 10
            matching_criteria.append(f"{property['acreage']} acres")
    else:
        score += 5

    # Views bonus (optional but nice)
    buyer_views = buyer.get('views_required', [])
    property_views = property.get('views', '') or ''
    if buyer_views and property_views:
        for view in buyer_views:
            if view.lower() in property_views.lower():
                matching_criteria.append(f"{view} views")
                break

    # Water features bonus
    buyer_water = buyer.get('water_features', [])
    property_water = property.get('water_features', '') or ''
    if buyer_water and property_water:
        for water in buyer_water:
            if water.lower() in property_water.lower():
                matching_criteria.append(f"{water}")
                break

    # Normalize to 0-100
    final_score = int((score / max_score) * 100) if max_score > 0 else 0

    return final_score, matching_criteria


def check_already_alerted(contact_id: str, property_id: str) -> bool:
    """Check if we've already sent an alert for this property to this contact."""
    conn = get_db_connection()

    try:
        existing = conn.execute('''
            SELECT id FROM alert_log
            WHERE alert_type = 'new_listing'
            AND contact_id = ?
            AND property_id = ?
        ''', [contact_id, property_id]).fetchone()

        return existing is not None

    finally:
        conn.close()


def log_alert(alert_type: str, contact_id: str, property_id: str, email_to: str,
              status: str = 'sent', error_message: str = None) -> None:
    """Log an alert to prevent future duplicates."""
    conn = get_db_connection()

    try:
        conn.execute('''
            INSERT INTO alert_log (alert_type, contact_id, property_id, email_to, status, error_message)
            VALUES (?, ?, ?, ?, ?, ?)
            ON CONFLICT(alert_type, contact_id, property_id) DO UPDATE SET
            sent_at = CURRENT_TIMESTAMP,
            status = excluded.status,
            error_message = excluded.error_message
        ''', [alert_type, contact_id, property_id, email_to, status, error_message])
        conn.commit()
    finally:
        conn.close()


def match_listings_to_buyers(listings: List[Dict], buyers: List[Dict]) -> Dict[str, List[Dict]]:
    """
    Match new listings to buyers based on requirements.

    Returns:
        Dictionary mapping contact_id to list of matching properties
    """
    matches = {}

    # Get threshold from database settings
    match_threshold = get_db_setting('new_listing_match_threshold', 60)
    logger.info(f"Using match threshold: {match_threshold}")

    for buyer in buyers:
        buyer_matches = []

        for listing in listings:
            # Skip if already alerted
            if check_already_alerted(buyer['id'], listing['id']):
                continue

            score, criteria = calculate_match_score(listing, buyer)

            if score >= match_threshold:
                match = listing.copy()
                match['match_score'] = score
                match['matching_features'] = ', '.join(criteria)
                match['is_price_drop'] = False  # Could enhance to detect
                buyer_matches.append(match)

        if buyer_matches:
            # Sort by match score descending
            buyer_matches.sort(key=lambda x: x['match_score'], reverse=True)
            matches[buyer['id']] = {
                'buyer': buyer,
                'properties': buyer_matches
            }

    return matches


def build_criteria_summary(buyer: Dict) -> str:
    """Build a human-readable summary of buyer's criteria."""
    parts = []

    if buyer.get('price_min') or buyer.get('price_max'):
        price_min = buyer.get('price_min', 0)
        price_max = buyer.get('price_max')
        if price_max:
            parts.append(f"${price_min:,}-${price_max:,}")
        else:
            parts.append(f"${price_min:,}+")

    if buyer.get('beds_min'):
        parts.append(f"{buyer['beds_min']}+ beds")

    if buyer.get('counties'):
        parts.append(', '.join(buyer['counties'][:2]))

    return ' | '.join(parts) if parts else 'Open criteria'


def send_listing_alerts() -> Dict[str, int]:
    """
    Main function to send new listing alerts to matching buyers.

    Returns:
        Dictionary with counts of emails sent, skipped, failed
    """
    logger.info("Starting new listing alerts...")

    stats = {'sent': 0, 'skipped': 0, 'failed': 0, 'properties_matched': 0, 'notes_pushed': 0}

    # Check if alerts are enabled
    if not get_db_setting('alerts_global_enabled', True):
        logger.info("Global alerts are disabled - exiting")
        return stats

    if not get_db_setting('new_listing_alerts_enabled', True):
        logger.info("New listing alerts are disabled - exiting")
        return stats

    # Get lookback hours from settings
    lookback_hours = get_db_setting('alert_lookback_hours', 24)
    logger.info(f"Looking back {lookback_hours} hours for new listings")

    # Get new listings
    listings = get_new_listings(lookback_hours)

    if not listings:
        logger.info("No new listings found")
        return stats

    # Get active buyers
    buyers = get_active_buyers()

    if not buyers:
        logger.info("No active buyers found")
        return stats

    # Match listings to buyers
    matches = match_listings_to_buyers(listings, buyers)

    logger.info(f"Found matches for {len(matches)} buyers")

    # Send emails to each buyer with matches
    for contact_id, match_data in matches.items():
        buyer = match_data['buyer']
        properties = match_data['properties']

        if not buyer.get('email'):
            stats['skipped'] += 1
            continue

        # Get max properties per alert from settings
        max_properties = get_db_setting('max_properties_per_alert', 10)

        # Prepare template context
        context = {
            'contact_name': f"{buyer['first_name']}",
            'property_count': len(properties),
            'properties': properties[:max_properties],  # Limit per settings
            'criteria_summary': build_criteria_summary(buyer),
            'alert_date': datetime.now().strftime('%B %d, %Y'),
            'agent_name': config.AGENT_NAME,
            'agent_email': config.AGENT_EMAIL,
            'agent_phone': config.AGENT_PHONE,
            'agent_headshot': config.AGENT_HEADSHOT_URL,
            'brokerage_name': config.BROKERAGE_NAME
        }

        # Build subject line
        if len(properties) == 1:
            subject = f"New Listing Alert: {properties[0]['address']}"
        else:
            subject = f"New Listings: {len(properties)} properties match your criteria"

        # Send email
        success = send_template_email(
            to=buyer['email'],
            subject=subject,
            template_name='listing_alert.html',
            context=context,
            from_name=config.AGENT_NAME
        )

        if success:
            stats['sent'] += 1
            stats['properties_matched'] += len(properties)

            # Log all alerts to prevent duplicates
            for prop in properties:
                log_alert('new_listing', contact_id, prop['id'], buyer['email'])

            logger.info(f"Sent {len(properties)} listing alerts to {buyer['email']}")

            # Push matched properties to FUB as a note
            if push_matches_to_fub(buyer, properties):
                stats['notes_pushed'] += 1
        else:
            stats['failed'] += 1

            # Log as failed
            for prop in properties:
                log_alert('new_listing', contact_id, prop['id'], buyer['email'],
                         status='failed', error_message='Email send failed')

            logger.error(f"Failed to send alerts to {buyer['email']}")

    logger.info(f"Listing alerts complete: {stats}")
    return stats


# ==========================================
# Price Drop Alerts
# ==========================================

def get_price_drops(hours: int = 24, min_drop_pct: float = 5.0) -> List[Dict[str, Any]]:
    """
    Get significant price drops.
    Note: property_changes table dropped during Navica migration.
    Will be rebuilt by Navica sync change detection.
    """
    logger.info("Price drop detection disabled (pending Navica change tracking)")
    return []


def match_price_drops_to_buyers(drops: List[Dict], buyers: List[Dict]) -> Dict[str, Dict]:
    """
    Match price drops to buyers based on their requirements.

    Returns:
        Dictionary mapping contact_id to dict with buyer and matched price drops
    """
    matches = {}

    # Get threshold from database settings (lower threshold for price drops)
    match_threshold = get_db_setting('price_drop_match_threshold', 50)
    logger.info(f"Using price drop match threshold: {match_threshold}")

    for buyer in buyers:
        buyer_matches = []

        for drop in drops:
            # Check if already alerted for this property (any alert type)
            if check_already_alerted(buyer['id'], drop['id']):
                continue

            score, criteria = calculate_match_score(drop, buyer)

            if score >= match_threshold:
                match = drop.copy()
                match['match_score'] = score
                match['matching_features'] = ', '.join(criteria)
                match['is_price_drop'] = True
                buyer_matches.append(match)

        if buyer_matches:
            # Sort by drop percentage descending (biggest drops first)
            buyer_matches.sort(key=lambda x: x['drop_pct'], reverse=True)
            matches[buyer['id']] = {
                'buyer': buyer,
                'properties': buyer_matches
            }

    return matches


def send_price_drop_alerts() -> Dict[str, int]:
    """
    Send price drop alerts to matching buyers.

    Returns:
        Dictionary with counts of emails sent, skipped, failed
    """
    logger.info("Starting price drop alerts...")

    stats = {'sent': 0, 'skipped': 0, 'failed': 0, 'properties_matched': 0, 'notes_pushed': 0}

    # Check if alerts are enabled
    if not get_db_setting('alerts_global_enabled', True):
        logger.info("Global alerts are disabled - exiting")
        return stats

    if not get_db_setting('price_drop_alerts_enabled', True):
        logger.info("Price drop alerts are disabled - exiting")
        return stats

    # Get lookback hours and minimum drop percentage from settings
    lookback_hours = get_db_setting('alert_lookback_hours', 24)
    min_drop_pct = get_db_setting('min_price_drop_pct', 5.0)

    logger.info(f"Looking for price drops >= {min_drop_pct}% in last {lookback_hours} hours")

    # Get price drops
    drops = get_price_drops(lookback_hours, min_drop_pct)

    if not drops:
        logger.info("No significant price drops found")
        return stats

    # Get active buyers
    buyers = get_active_buyers()

    if not buyers:
        logger.info("No active buyers found")
        return stats

    # Match drops to buyers
    matches = match_price_drops_to_buyers(drops, buyers)

    logger.info(f"Found price drop matches for {len(matches)} buyers")

    # Send emails to each buyer with matches
    for contact_id, match_data in matches.items():
        buyer = match_data['buyer']
        properties = match_data['properties']

        if not buyer.get('email'):
            stats['skipped'] += 1
            continue

        # Get max properties per alert from settings
        max_properties = get_db_setting('max_properties_per_alert', 10)

        # Prepare template context
        context = {
            'contact_name': f"{buyer['first_name']}",
            'property_count': len(properties),
            'properties': properties[:max_properties],
            'criteria_summary': build_criteria_summary(buyer),
            'alert_date': datetime.now().strftime('%B %d, %Y'),
            'agent_name': config.AGENT_NAME,
            'agent_email': config.AGENT_EMAIL,
            'agent_phone': config.AGENT_PHONE,
            'agent_headshot': config.AGENT_HEADSHOT_URL,
            'brokerage_name': config.BROKERAGE_NAME,
            'is_price_drop_alert': True
        }

        # Build subject line
        if len(properties) == 1:
            prop = properties[0]
            subject = f"Price Drop Alert: {prop['address']} - Now ${prop['price']:,} (-{prop['drop_pct']}%)"
        else:
            subject = f"Price Drop Alert: {len(properties)} properties reduced"

        # Send email (use same template, it handles price drops)
        success = send_template_email(
            to=buyer['email'],
            subject=subject,
            template_name='listing_alert.html',
            context=context,
            from_name=config.AGENT_NAME
        )

        if success:
            stats['sent'] += 1
            stats['properties_matched'] += len(properties)

            # Log alerts and mark as notified
            conn = get_db_connection()
            try:
                for prop in properties:
                    log_alert('price_drop', contact_id, prop['id'], buyer['email'])

                    # Mark the price change as notified
                    conn.execute('''
                        UPDATE property_changes SET notified = 1
                        WHERE id = ?
                    ''', [prop.get('change_id')])
                conn.commit()
            finally:
                conn.close()

            logger.info(f"Sent {len(properties)} price drop alerts to {buyer['email']}")

            # Push to FUB
            if push_matches_to_fub(buyer, properties):
                stats['notes_pushed'] += 1
        else:
            stats['failed'] += 1

            for prop in properties:
                log_alert('price_drop', contact_id, prop['id'], buyer['email'],
                         status='failed', error_message='Email send failed')

            logger.error(f"Failed to send price drop alerts to {buyer['email']}")

    logger.info(f"Price drop alerts complete: {stats}")
    return stats


def main():
    """Entry point for cron job - runs both new listing and price drop alerts."""
    import sys

    all_stats = {
        'new_listing': {'sent': 0, 'failed': 0},
        'price_drop': {'sent': 0, 'failed': 0}
    }

    # Run new listing alerts
    stats = send_listing_alerts()
    all_stats['new_listing'] = stats

    # Run price drop alerts
    stats = send_price_drop_alerts()
    all_stats['price_drop'] = stats

    # Log combined stats
    total_sent = all_stats['new_listing']['sent'] + all_stats['price_drop']['sent']
    total_failed = all_stats['new_listing']['failed'] + all_stats['price_drop']['failed']

    logger.info(f"All alerts complete - Total sent: {total_sent}, Total failed: {total_failed}")

    # Exit with error if all sends failed
    if total_failed > 0 and total_sent == 0:
        sys.exit(1)

    sys.exit(0)


if __name__ == '__main__':
    main()
